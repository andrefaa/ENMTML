% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ENMTML.R
\name{ENMTML}
\alias{ENMTML}
\title{Create and process Ecological Niche and Species Distribution Models}
\usage{
ENMTML(pred_dir, proj_dir = NULL, occ_file, sp, x, y, min_occ = 10,
  thin_occ = NULL, eval_occ = NULL, colin_var = NULL,
  imp_var = FALSE, sp_accessible_area = NULL, pseudoabs_method,
  pres_abs_ratio = 1, part, save_part = FALSE, save_final = TRUE,
  algorithm, thr, msdm = NULL, ensemble = NULL,
  extrapolation = FALSE, cores = 1)
}
\arguments{
\item{pred_dir}{character. Directory path with predictors (file formats supported are: ASC, BILL, TIFF or TXT)}

\item{proj_dir}{character. Directory path containing folders with predictors for different regions or time periods used to project models (file formats supported are: ASC, BILL, TIFF or TXT).}

\item{occ_file}{character. Directory path with tab-delimited TXT file with species names, latitude and longitude}

\item{sp}{character. Name of the column with information about species names}

\item{x}{character. Name of the column with information about longitude}

\item{y}{character. Name of the column with information about latitude}

\item{min_occ}{integer. Minimum number of unique occurrences (species with less than this number will be excluded)}

\item{thin_occ}{character Default NULL. Perform spatial filtering (Thinning, based on spThin package) on the presences. For this augment it is necessary provide a vector in which its elements need to have the names 'method' or 'method' and 'distance' (more information below). Three thinning methods are available:
\itemize{
\item MORAN-Distance defined by Moran Variogram, usage thin_occ=c(method='MORAN').
\item CELLSIZE-Distance defined by 2x cellsize (Haversine Transformation), usage thin_occ=c(method='CELLSIZE').
\item USER-DEFINED-User defined distance. For this option it is neede provide a vector with two values. Usage thin_occ=c(method='USER-DEFINED', ditance='300'). The second numeric value refers to the distance in km that will be used for thinning. So distance=300 means that all records within a radius of 300 km will be deleted
}}

\item{eval_occ}{character. Directory path with tab-delimited TXT file with species names, latitude and longitude, this three columns must have the same columns names than the databased used in the occ_file argument. This is an external occurrence database that will be used to external models validation. (default NULL)}

\item{colin_var}{character. Method to reduce variable collinearity:
\itemize{
  \item PCA: Perform a Principal Component Analysis on predictors and use Principal Components as environmental variables, usage colin_var=c(method='PCA').
  \item VIF: Variance Inflation Factor (Chatterjee and Hadi 2006), , usage colin_var=c(method='VIF').
  \item PEARSON: Select variables by Pearson correlation, a threshold of maximum correlation must be specified by user, usage colin_var=c(method='PEARSON', threshold='0.7').
}}

\item{imp_var}{logical Perform variable importance and curves response for selected algorithms? (defaul FALSE)}

\item{sp_accessible_area}{character. Restrict for each species the accessible area, i.e., the area used to construct the model. It is necessary to provide a vector for this argument. Three methods were implemented
\itemize{
  \item BUFFER and based on maximum distance among pair of occurrences for each species. Usage sp_accessible_area=c(method='BUFFER', type='1').
  \item BUFFER and based on A single buffer for all species expressed in km. Usage sp_accessible_area=c(method='BUFFER', type='2', width='300').
  \item MASK: this method consist in delimit the area used to model calibration based on the polygon where a species occurrences fall. For instance it is possible delimit the calibration area based on ecorregion shapefile. For this option it is necessary inform the path to the file that will be used as mask. Next file format can be loaded '.bil', '.asc', '.tif', '.shp', and '.txt'. Usage sp_accessible_area=c(method='MASK', filepath='C:/Users/mycomputer/ecoregion/olson.shp').
}}

\item{pseudoabs_method}{character. Pseudo-absence allocation method. It is necessary to provide a vector for this argument. Only one method can be chosen. The next methods are implemented:
\itemize{
\item RND: Random allocation throughout area used to fit models. Usage pseudoabs_method=c(method='RND').
\item ENV_CONST: Pseudo-absences are environmentally constrained to a region with lower suitability values predicted by a Bioclim model. Usage pseudoabs_method=c(method='ENV_CONST').
\item GEO_CONST: Pseudo-absences are allocated far from occurrences based on a geographical buffer. For this method it is necessary provie a second value wich express the buffer width in km. Usage pseudoabs_method=c(method='GEO_CONST', width='50').
\item GEO_ENV_CONST: Pseudo-absences are constrained environmentally (based on Bioclim model) but distributed geographically far from occurrences based on a geographical buffer. For this method it is necessary provie a second value wich express the buffer width in km. Usage pseudoabs_method=c(method='GEO_ENV_CONST', width='50')
\item GEO_ENV_KM_CONST: Pseudo-absences are constrained on a three-level procedure; it is similar to the GEO_ENV_CONST with an additional step which distributes the pseudo-absences in the environmental space using k-means cluster analysis. For this method it is necessary provie a second value wich express the buffer width in km. Usage pseudoabs_method=c(method='GEO_ENV_KM_CONST', width='50')
}}

\item{pres_abs_ratio}{numeric. Presence-Absence ratio (values between 0 and 1)}

\item{part}{character. Partition method for model's validation. Only one method can be chosen. It is necessary to provide a vector for this argument. The next methods are implemented:
\itemize{
  \item BOOT: Random bootstrap partition (e.g. 70 % training and 30 % test). Usage â€¢    part=c(method='BOOT', replicates='2',  proportion='0.7'). 'replicate' refers to the number of replicates, it assumes a value >=1. 'proportion' refres to the proportion of occurrences used for fitting the model, it assumes a value >0 and <=1.
  \item KFOLD: Random partition in k-fold cross-validation. Usage part=c(method= 'KFOLD', folds='5'). 'folds' referes to the number of k-folds for patitioning, it assume value >=1.
  \item BANDS: Geographic partition structured as bands (latitudinal(1) or longitudinal(2)). Usage part=c(method= 'BANDS', type='1'). 'type' refers to the bands disposition
  \item BLOCK: Geographic partition structured as a checkerboard. Usage part=c(method= 'BLOCK').
}}

\item{save_part}{logical. If TRUE, function will save .tif files of partial models, i.e. model created by each occurrence partitions. (default FALSE).}

\item{save_final}{logical. If TRUE, function will Save .tif files of the final model, i.e. fitted with all occurrences data. (default TRUE)}

\item{algorithm}{character. Algorithm to construct ecological niche models (it is possible to use more than one method):
\itemize{
  \item BIO: Bioclim
  \item MAH: Mahalanobis
  \item DOM: Domain
  \item ENF: Ecological Niche Factor Analysis
  \item MXS: Maxent Simple (only linear and quadratic features, based on MaxNet package)
  \item MXD: Maxent Default (all features, based on MaxNet package)
  \item SVM: Support Vector Machine
  \item GLM: Generalized Linear Model
  \item GAM: Generalizes Additive Model
  \item BRT: Boosted Regression Tree
  \item RDF: Random Forest
  \item MLK: Maximum Likelihood
  \item GAU: Gaussian Process
}}

\item{thr}{character. Threshold used for presence-absence predictions. It is possible to use more than one threshol type. It is necessary to provide a vector for this argument:
\itemize{
  \item LPT: The highest threshold at which there is no omission. Usage thr=c(type='LPT').
  \item MAX_TSS: Threshold at which the sum of the sensitivity and specificity is highest.
  Usage thr=c(type='MAX_TSS').
  \item MAX_KAPPA: The threshold at which kappa is highest ("max kappa"). Usage thr=c(type='MAX_KAPPA').
  \item SENSITIVITY: Fixed (specified) sensitivity. For this type of threshold thr must be use as thr=c(type='SENSITIVITY', sens='0.6'). 'sens' refers to models will be bynarized using this suitability value. Note that this method assume 'sens' value for all algorithm.
  \item JACCARD: The threshold at which Jaccard is highest. Usage thr=c(type='JACCARD').
  \item SORENSEN: The threshold at which Sorensen is highest. Usage thr=c(type='SORENSEN').
  }
In the case of use more than one threshold type it is necessary concatenate the names of threshold types, e.g., thr=c(type=c('LPT', 'MAX_TSS', 'JACCARD')). In the case of SENSITIVITY threshold is used it is necessayr specify the desired sensitivity value, e.g. thr=c(type=c('LPT', 'MAX_TSS', 'SENSITIVITY'), sens='0.8')}

\item{msdm}{character. Include spatial restrictions. These methods restrict ecological niche models in order to have less potential prediction and turn models closer to species distribution models. They are classified in a Priori and a Posteriori methods. The firt one encompase method taht include geographical layers as predictor of models construction, whereas a Posteriori constrain models based on occurrence and suitability pattenrs. This argument is filled only wiht a method, in the case of use MCP-B method msdm is filled in a different way se below:

a Priori methods:

\itemize{
  \item XY: Create two layers latitude and longitude layer (added as a predictor).Usage msdm=c(method='XY').
  \item MIN: Create a layer with information of the distance from each cell to the closest occurrence (added as a predictor).Usage msdm=c(method='MIN').
  \item CML: Create a layer with information of the summed distance from each cell to ALL occurrences (added as a predictor).Usage msdm=c(method='CML').
  \item KER: Create a layer with a Gaussian-Kernel on the occurrence data (added as a predictor).Usage msdm=c(method='KER').
  }
a Posteriori methods
\itemize{
  \item OBR: Occurrence based restriction, uses the distance between points to exclude far suitable patches (Mendes et al., in prep).Usage msdm=c(method='OBR').
  \item LR: Lower Quantile, select the nearest 25% patches (Mendes et al., in prep).Usage msdm=c(method='LR').
  \item PRES: Select only the patches with confirmed occurrence data (Mendes et al, in prep).Usage msdm=c(method='PRES').
  \item MCP: Excludes suitable cells outside the Minimum Convex Polygon of the occurrence data.Usage msdm=c(method='MCP').
  \item MCP-B: Creates a Buffer around the MCP (distance defined by user in km). Usage msdm=c(method='MCP-B', width=100).
  }}

\item{ensemble}{character. Method used to ensemble different algorithms. It is possible to use more than one method. It is necessary to provide a vector for this argument.  It is possible to use more than one ensemble method. For SUP, W_MEAN or PCA_SUP method it is necesary provide an evaluation metric to ensemble arguemnts (i.e. AUC, Kappa, TSS, Jaccard, Sorensen or Fpb) see below. (default NULL):
  \itemize{
  \item MEAN: Simple average of the different models. Usage ensemble=c(method='MEAN').
  \item W_MEAN: Weighted average. Usage ensemble=c(method='W_MEAN').
  \item SUP: Average of the best models (TSS over the average). Usage ensemble=c(method='SUP').
  \item PCA: Performs a Principal Component Analysis (PCA) and returns the first axis. Usage ensemble=c(method='PCA').
  \item PCA_SUP: PCA of the best models (TSS over the average). For this metdhos it is necesary provide an evaluation metric. Usage ensemble=c(method='PCA_SUP', metric='Fpd').
  \item PCA_THR: PCA only with cells above the threshold. Usage ensemble=c(method='PCA_THR').
  }

 In the case of use more than one ensemble method it is necessary concatenate the names of ensemble mehtods within the argument, e.g., ensemble=c(type=c('MEAN', 'PCA')), ensemble=c(method=c('MEAN, 'W_MEAN', 'PCA_SUP'), metric='Fpb')}

\item{extrapolation}{logical. If TRUE the function will calculate extrapolation based on Mobility-oriented parity (MOP) method, for current and future conditions.}

\item{cores}{numeric. Define the number number of CPU cores to run modeling procedures in parallel.}
}
\description{
Create and process Ecological Niche and Species Distribution Models
}
\examples{
require(ENMTML)
require(raster)

##\%######################################################\%##
#                                                          #
####           Directories and data creation            ####
#                                                          #
##\%######################################################\%##
# ENMTML package account with some bioclimantic variables
# used to test ENMTML function.
# In order to simulate the files and folders needed for an ENMTML function
# will be created different folders with some data

# First will be created a folder with a working directory
getwd() #' Working directory of R session
d_ex <- file.path(getwd(), 'ENMTML_example')
d_ex
dir.create(d_ex)

# Will be saved some ENMTML data sets to ENMTML_example folder
# Virtual species occurrences
data("occ")
d_occ <- file.path(d_ex, 'occ.txt')
write.table(occ, d_occ, sep = '\\t', row.names = F)
# Five bioclimatic variables for current conditions
data("env")
d_env <- file.path(d_ex, 'current_env_var')
dir.create(d_env)
writeRaster(env, file.path(d_env, names(env)), bylayer=T, format='GTiff')
# Five bioclimatic variables for future conditions
# (for more details see predictors_future help)
data("env_fut")
d_fut <- file.path(d_ex, 'future_env_var')
dir.create(d_fut)
d0 <- file.path(d_fut, names(env_fut))
sapply(d0, dir.create)

writeRaster(env_fut$`2080_4.5`, file.path(d0[1],
            names(env_fut$`2080_4.5`)), bylayer=T, format='GTiff')
writeRaster(env_fut$`2080_8.5`, file.path(d0[2],
            names(env_fut$`2080_8.5`)), bylayer=T, format='GTiff')

# Polygon of terrestrial ecoregion
data("ecoregions")
d_eco <- file.path(d_ex, 'ecoregions')
dir.create(d_eco)
d_eco <- file.path(d_eco, paste0('eco','.shp'))
shapefile(ecoregions, d_eco)

# shell.exec(d_ex) # open the directory and folders created
rm(list = c('d0', 'd_ex', 'ecoregions', 'env', 'env_fut', 'occ'))

# Now we have the minimum data needed to create models with ENMTML package
# a directory with environmental rasters and a .txt file with occurrence


##\%######################################################\%##
#                                                          #
####           Construction ENM with ENMTML            ####
#                                                          #
##\%######################################################\%##
args(ENMTML)

# ENMTML provides a variety of tools to build different models
# depending on the modeling objetives.
# Here will be provided a single modeling procedure.
# For more example and exploration of models
# see <https://github.com/andrefaa/ENMTML>

# Will be fitted models for five virtual species with
# current and future conditions. Please read ENMTML arguments.

# The next object contains the directory and file path data and folders that will be used
d_occ # file path with species occurrences
d_env # directory path with current environmental conditions (raster in tiff format)
d_fut # directory path with folders with future environmental conditions (raster in tiff format)
d_eco # file path with shapefile used to constrain models


ENMTML(
 pred_dir = d_env,
 proj_dir = NULL,
 occ_file = d_occ,
 sp = 'species',
 x = 'x',
 y = 'y',
 min_occ = 10,
 thin_occ = NULL,
 eval_occ = NULL,
 colin_var = c(method='PCA'),
 imp_var = FALSE,
 sp_accessible_area = c(method='BUFFER', type='2', width='500'),
 pseudoabs_method = c(method = 'RND'),
 pres_abs_ratio = 1,
 part=c(method= 'KFOLD', folds='2'),
 save_part = FALSE,
 save_final = TRUE,
 algorithm = c('SVM', 'RDF', 'MXD'),
 thr = c(type='MAX_TSS'),
 msdm = NULL,
 ensemble = c(method='PCA'),
 extrapolation = FALSE,
 cores = 1
)

# ENMTML function will create a folder named Result a directory
# prior to the directory specified in the pred_dir argument

d_env # Directory used to define environmental variables
d_rslt <- d_env \%>\% dirname() \%>\% file.path(., 'Result')
d_rslt
# shell.exec(d_rslt) # for Windows users
# List of txt files and subdirectories
list.files(d_rslt)
list.dirs(d_rslt)



}
